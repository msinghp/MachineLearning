---
title: ''
output:
  html_document:
    keep_md: yes
  word_document: default
---
#### Assessment of the eficacy of Exercise Activity

#####Loading the required Libraries

```{r echo=FALSE}
library(randomForest)
library(class) 
library(e1071)      		   
library(caret)
```




##### Executive Summary

The exercise activity data provided  was analyzed to find out whether it was possible to predict how well the exercise was performed. Using the randomforest algorithm yielded  a 99% accuracy in predicting how well the exercises was performed

#####Introduction

Devices such as Jawbone Up, Nike FuelBand, and Fitbit  have been utilized  by tech geek health enthusiasts  to collect exercise data in an effort to improve their health. While the amount of exercise is often collected, how well the exercise is done is seldom quantified. The current  data tracks data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants who were asked to perform barbell lifts correctly and incorrectly in 5 different ways.


#####Data Description

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

Trainging  data came from:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data came from:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

#####How model was built

The model was generated as follows:

The pml-training data was split 60:40 into a training set and a testing set. The training file was used to trian the model using the random forest algorithm. The tesing file was used to test the model generated by the random forest algorithm. The random forest algorithm was chosen for the following reasons ( modified from https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#overview)

1. Compared to other algorithms,it has high accuracy
2. Runs efficiently on large data sets
3. It can handle large numbers of of input variables



#####The project was done in the following phases:

1. Feature selection

2. Build the model using the training data

3. Running the model against the testing set

4. Run the model against the 20 data cases

5.  Evaluate the model statistics




##### 1.0 Feature Selection

Features were selected using the following process

1. Removing the first eight columns since they contain pesonal identification data.

2. Remove all calculated fields such as standard deviation since they are derived from the existing data

3. Remove all columns that mostly contain NAs

The above process resulted in the selection of 36 features

```{r, echo=TRUE}
tr <- read.csv("pml-training.csv", na.strings=c("#DIV/0!","NA") )
tr <- tr[,c(9:160)]
r <- grep('kur*|std*|skew*|max*|min*|var*|avg*|tot*|user|new|X|num',colnames(tr))
tr <- tr[-r]
nacols <- c((colSums(!is.na(tr[,-ncol(tr)])) >= 0.6*nrow(tr)))
tr <- tr[,nacols]
tr$classe <- factor(tr$classe)

```


###### 2. Build the model using the training data

The following results were obtained when the training data set was used to generate the model

```{r, echo=TRUE}
set.seed(157)
trainIndex <- createDataPartition(tr$classe, p=0.60, list=FALSE)
training<- tr[ trainIndex,]
testing<- tr[-trainIndex,]
model <- randomForest(classe~.,data=training)
testclass <- predict(model, testing)
cfMatrix <- confusionMatrix(testclass, testing$classe) 
model

```
 
#####3. Running the model against the testing set
 
Running the model aginst the the testing set yielded the following statistics forthe confusion matrix
 
```{r, echo=TRUE}
cfMatrix
```



###### 4. Run the model against the 20 data cases

The ml-testing.csv file contained 20 test cases. The file was subjected to the same data cleaning techniques as was used with the pml-training.csv file that was used to generate the model

```{r, echo=TRUE}

ev <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!") )
ev <- ev[,c(9:160)]
ev <- ev[-r]
ev <- ev[,nacols]
testclass1 <- predict(model, ev)
testclass1



```
###### 5.  Evaluate the model statistics

```{r, echo=FALSE,fig.width=5.5, fig.height=5.5}

 varImpPlot(model,main="")
 
```

The matrix indicates how important that variable is in classifying the data. The plot shows the importance of each variable with the most importanct variable at the top of the list.

#####Conclusion

The goal of the study was to findout if was possible predict how well specific  exercises were performed.Using  the random forest algorithm, it was possible to predict how well the exercise regimen was performed with a high degree of accuracy.



